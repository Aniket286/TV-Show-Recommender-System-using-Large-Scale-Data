{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df = pd.read_csv('data/anime.csv', \n",
    "                      usecols=['MAL_ID', 'Episodes', 'Premiered', 'Duration', 'Genres', 'Score', ])\n",
    "ratings_df = pd.read_csv('data/rating_complete.csv')\n",
    " \n",
    "def convert_episodes(ep):\n",
    "    try:\n",
    "        return float(ep)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "def convert_duration(duration):\n",
    "    if pd.isna(duration):\n",
    "        return np.nan\n",
    "    if not isinstance(duration, str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        if 'hr' in duration and 'min' in duration:\n",
    "            parts = duration.split()\n",
    "            hours = float(parts[0])\n",
    "            minutes = float(parts[2])\n",
    "            return hours * 60 + minutes\n",
    "        elif 'hr' in duration:\n",
    "            hours = float(duration.split()[0])\n",
    "            return hours * 60\n",
    "        elif 'min' in duration:\n",
    "            return float(duration.split()[0])\n",
    "    except (ValueError, IndexError):\n",
    "        return np.nan\n",
    "\n",
    "def extract_year(premiered):\n",
    "    if isinstance(premiered, str):\n",
    "        match = re.search(r'\\d{4}', premiered)\n",
    "        return float(match.group()) if match else np.nan\n",
    "    return np.nan\n",
    "\n",
    "anime_features = anime_df.copy()\n",
    "\n",
    "anime_features['Episodes'] = pd.to_numeric(anime_features['Episodes'], errors='coerce')\n",
    "anime_features['Duration_minutes'] = anime_features['Duration'].apply(convert_duration)\n",
    "anime_features['year'] = anime_features['Premiered'].apply(extract_year)\n",
    "anime_features['Score'] = pd.to_numeric(anime_features['Score'], errors='coerce')\n",
    "\n",
    "genres = anime_features['Genres'].str.get_dummies(sep=', ')\n",
    "anime_features['Encoded_Genres'] = genres.apply(\n",
    "    lambda row: ''.join(row.astype(str)), \n",
    "    axis=1\n",
    ").apply(lambda row: int(row, 2))\n",
    "\n",
    "anime_features['Season'] = anime_features['Premiered'].str.extract(r'(Spring|Summer|Fall|Winter)')\n",
    "seasons = pd.get_dummies(anime_features['Season'], prefix='Season', dummy_na=True).astype('int')\n",
    "\n",
    "anime_features[\"enc_season\"] = seasons.apply(\n",
    "    lambda row: ''.join(row.astype(str)), \n",
    "    axis=1\n",
    ").apply(lambda row: int(row, 2))\n",
    "\n",
    "features = pd.concat([\n",
    "    anime_features[['MAL_ID']].astype('int32'),\n",
    "    anime_features[['Episodes', 'Duration_minutes', 'Score', 'year']].astype('float32'),\n",
    "    anime_features['Encoded_Genres'].astype('int64'),\n",
    "    anime_features[\"enc_season\"].astype('int8')\n",
    "], axis=1)\n",
    "\n",
    "features = features.fillna({\n",
    "    'Episodes': features['Episodes'].median(),\n",
    "    'Duration_minutes': features['Duration_minutes'].median(),\n",
    "    'Score': features['Score'].median(),\n",
    "    'year': features['year'].median()\n",
    "})\n",
    "\n",
    "\n",
    "Anime_ID_map = {anime_id: i for i, anime_id in enumerate(features['MAL_ID'])}\n",
    "Genere_index = genres.columns\n",
    "Seaon_index = seasons.columns\n",
    "\n",
    "del anime_features, genres, seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4858264923095703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Duration_minutes</th>\n",
       "      <th>Score</th>\n",
       "      <th>year</th>\n",
       "      <th>Encoded_Genres</th>\n",
       "      <th>enc_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>14431090147584</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>8933536203008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.24</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>14431090149376</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>8933671436320</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.98</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>4432406251552</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID  Episodes  Duration_minutes  Score    year  Encoded_Genres  \\\n",
       "0       1      26.0              24.0   8.78  1998.0  14431090147584   \n",
       "1       5       1.0             115.0   8.39  2010.0   8933536203008   \n",
       "2       6      26.0              24.0   8.24  1998.0  14431090149376   \n",
       "3       7      26.0              25.0   7.27  2002.0   8933671436320   \n",
       "4       8      52.0              23.0   6.98  2004.0   4432406251552   \n",
       "\n",
       "   enc_season  \n",
       "0           8  \n",
       "1           1  \n",
       "2           8  \n",
       "3           4  \n",
       "4          16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features.memory_usage(deep=True).sum() / 1024**2)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_remap(value, bit_size = 44):\n",
    "    binary_str = f\"{value:0{bit_size}b}\" \n",
    "    binary_vector = np.array([int(bit) for bit in binary_str])\n",
    "    return binary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 1, 0, 0, 0]\n",
       "1    [0, 0, 0, 0, 1]\n",
       "2    [0, 1, 0, 0, 0]\n",
       "3    [0, 0, 1, 0, 0]\n",
       "4    [1, 0, 0, 0, 0]\n",
       "Name: enc_season, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"Encoded_Genres\"].head().apply(str_remap)\n",
    "features[\"enc_season\"].head().apply(partial(str_remap, bit_size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57633278"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df, _ =train_test_split(ratings_df, test_size=0.998, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115266"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain, ratingsTest = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "ratingsTrain, ratingsValid = train_test_split(ratingsTrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratingsTrain[\"user_id\"].unique()\n",
    "anime_per_user = {user: () for user in users}\n",
    "anime_per_user = ratingsTrain.groupby(\"user_id\")[\"anime_id\"].apply(list)\n",
    "anime_rating_per_user = ratingsTrain.groupby(\"user_id\")[\"rating\"].apply(list)\n",
    "for i, data in enumerate(anime_per_user.items()):\n",
    "    user, anime_list = data\n",
    "    ratings = torch.tensor(anime_rating_per_user[user], dtype=torch.float32)\n",
    "    anime_id_list = torch.tensor([Anime_ID_map[anime] for anime in anime_list], dtype=torch.int64)\n",
    "    anime_per_user[user] = (anime_id_list, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_min = float('inf')\n",
    "best_vals = None\n",
    "Num_epochs = 15\n",
    "\n",
    "def fit_model(lambda_reg, k=3, lr=0.01):\n",
    "    global mse_min, best_vals\n",
    "    n_users = len(users)\n",
    "    n_animes = len(Anime_ID_map)\n",
    "\n",
    "    alpha = torch.tensor(torch.mean(torch.tensor(ratingsTrain[\"rating\"].values, dtype=torch.float32)), requires_grad=True, device=\"cuda\")\n",
    "    beta_u = {user: torch.zeros(1, dtype=torch.float32, requires_grad=True, device=\"cuda\") for user in users}\n",
    "    beta_a = torch.zeros(n_animes, dtype=torch.float32, requires_grad=True, device=\"cuda\")\n",
    "    gamma_u = {user: torch.rand(k, dtype=torch.float32, requires_grad=True, device=\"cuda\") for user in users}\n",
    "    gamma_a = torch.rand(n_animes, k, dtype=torch.float32, requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    params = [alpha, *gamma_u.values(), gamma_a, *beta_u.values(), beta_a]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=lambda_reg)\n",
    "    mse = mse_on_validation(alpha, beta_u, beta_a, gamma_u, gamma_a)\n",
    "    print(f\"Initial MSE: {mse}\")\n",
    "    for epoch in range(Num_epochs):\n",
    "        for i,dt in enumerate(anime_per_user.items()):\n",
    "            user, anime_data = dt\n",
    "            anime_list, ratings = anime_data\n",
    "            ratings = ratings.to(\"cuda\")\n",
    "            pred = alpha + beta_u[user] + beta_a[anime_list] + torch.sum(gamma_u[user] * gamma_a[anime_list], dim=1)\n",
    "            loss = torch.mean((ratings - pred) ** 2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, {i}/{n_users}, Loss: {loss.item()}\")\n",
    "        mse = mse_on_validation(alpha, beta_u, beta_a, gamma_u, gamma_a)\n",
    "        print(f\"Epoch {epoch+1}, MSE: {mse}\")\n",
    "        if mse < mse_min:\n",
    "            mse_min = mse\n",
    "            best_vals = (alpha, beta_u, beta_a, gamma_u, gamma_a)\n",
    "\n",
    "def mse_on_validation(alpha, beta_u, beta_a, gamma_u, gamma_a):\n",
    "    sse = 0\n",
    "    for u, a, r in ratingsValid.values:\n",
    "        if u not in beta_u:\n",
    "            pred = alpha\n",
    "        else:\n",
    "            a_id = Anime_ID_map.get(a)\n",
    "            pred = alpha + beta_u[u] + beta_a[a_id] + torch.sum(gamma_u[u] * gamma_a[a_id])\n",
    "            pred = pred.item()\n",
    "        sse += (r - pred) ** 2\n",
    "    mse = sse / len(ratingsValid)\n",
    "    return mse\n",
    "\n",
    "fit_model(0.05, 5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(lambda_reg, k=3, initals = None, lr = 0.01):\n",
    "    global mse_min, best_vals\n",
    "    num_epochs = 20\n",
    "    learning_rate = lr\n",
    "\n",
    "    # Initialize biases\n",
    "    alpha = np.mean([r for _, _, r in ratingsTrain.values])\n",
    "    beta_u = defaultdict(float)\n",
    "    beta_i = defaultdict(float)\n",
    "    \n",
    "    # Initialize latent factors randomly\n",
    "    gamma_u = {u: np.random.normal(scale=0.05, size=k) for u in users}\n",
    "    gamma_i = {b: np.random.normal(scale=0.05, size=k) for b in animes}\n",
    "    \n",
    "    if initals:\n",
    "        alpha, beta_u, beta_i, gamma_u, gamma_i = initals\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        learning_rate*=0.99\n",
    "        for index,d in enumerate(ratingsTrain.values):\n",
    "            u, i, r = d\n",
    "            # Compute prediction\n",
    "            prediction = alpha + np.dot(gamma_u[u], gamma_i[i]) + beta_u[u] + beta_i[i]\n",
    "            error = r - prediction\n",
    "\n",
    "            # Update global bias\n",
    "            alpha += learning_rate * (error)\n",
    "\n",
    "            # Update user and item biases\n",
    "            beta_u[u] += learning_rate * (error - lambda_reg * beta_u[u])\n",
    "            beta_i[i] += learning_rate * (error - lambda_reg * beta_i[i])\n",
    "\n",
    "            # Update latent factors\n",
    "            gamma_u[u] += learning_rate * (error * gamma_i[i] - lambda_reg * gamma_u[u])\n",
    "            gamma_i[i] += learning_rate * (error * gamma_u[u] - lambda_reg * gamma_i[i])\n",
    "            if index % 1000000 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}, {index}/{len(ratingsTrain)}')\n",
    "        mse = mse_on_validation(alpha, beta_u, beta_i, gamma_u, gamma_i)\n",
    "        if mse < mse_min:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, MSE on validation set: {mse}')\n",
    "            mse_min = mse\n",
    "            best_vals = (alpha, beta_u, beta_i, gamma_u, gamma_i)\n",
    "\n",
    "    \n",
    "    return alpha, beta_u, beta_i, gamma_u, gamma_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
